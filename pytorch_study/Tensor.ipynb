{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Tensor"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "# 직접 생성\n",
    "data = [[1, 2],[3, 4]]\n",
    "x_data = torch.tensor(data)\n",
    "print(x_data)\n",
    "print(x_data.dtype)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)\n",
    "print(x_np)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Tensor: \n",
      " tensor([[1, 1],\n",
      "        [1, 1]]) \n",
      "\n",
      "Random Tensor: \n",
      " tensor([[0.4247, 0.7476],\n",
      "        [0.1939, 0.1899]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_ones = torch.ones_like(x_data) # x_data의 속성을 유지합니다.\n",
    "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
    "\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float) # x_data의 속성을 덮어씁니다.\n",
    "print(f\"Random Tensor: \\n {x_rand} \\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor: \n",
      " tensor([[0.0669, 0.9981, 0.8338],\n",
      "        [0.2049, 0.5495, 0.4410]]) \n",
      " torch.Size([2, 3]) \n",
      "\n",
      "Ones Tensor: \n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]]) \n",
      " torch.Size([2, 3]) \n",
      "\n",
      "Zeros Tensor: \n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]]) \n",
      " torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "shape = (2,3,)\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "print(f\"Random Tensor: \\n {rand_tensor} \\n {rand_tensor.shape} \\n\")\n",
    "print(f\"Ones Tensor: \\n {ones_tensor} \\n {ones_tensor.shape} \\n\")\n",
    "print(f\"Zeros Tensor: \\n {zeros_tensor} \\n {zeros_tensor.shape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "# 텐서의 속성(Attribute)\n",
    "tensor = torch.rand(3,4)\n",
    "\n",
    "print(f\"Shape of tensor: {tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {tensor.device}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "tensor = torch.rand(4, 4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row: tensor([0.4997, 0.0000, 0.1058, 0.2061])\n",
      "First column: tensor([0.4997, 0.1672, 0.0813, 0.9977])\n",
      "Last column: tensor([0.2061, 0.6372, 0.1055, 0.7101])\n",
      "tensor([[0.3738, 0.6372],\n",
      "        [0.1970, 0.1055],\n",
      "        [0.4878, 0.7101]])\n",
      "tensor([[0.4997, 0.0000, 0.1058, 0.2061],\n",
      "        [0.1672, 0.0000, 0.3738, 0.6372],\n",
      "        [0.0813, 0.0000, 0.1970, 0.1055],\n",
      "        [0.9977, 0.0000, 0.4878, 0.7101]])\n",
      "torch.Size([4, 4])\n"
     ]
    }
   ],
   "source": [
    "# 텐서의 연산(Operation)\n",
    "\n",
    "print(f\"First row: {tensor[0]}\")\n",
    "print(f\"First column: {tensor[:, 0]}\")\n",
    "print(f\"Last column: {tensor[..., -1]}\")\n",
    "\n",
    "# 슬라이싱을 실행할 때, 2차원이면 [ 1dim, 2dim]의 형태에서 [ x:y, x:y]의 형태로 슬라이싱을 실행할 수 있다.\n",
    "# ':' 하나만 입력하면 전체를 뜻하고 슬라이싱을 실행하면 해당 위치에서 가져온다.\n",
    "print(tensor[1:, 2:])\n",
    "print(tensor)\n",
    "print(tensor.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "torch.Size([4, 12])\n"
     ]
    }
   ],
   "source": [
    "# dim을 0으로 설정하면 1차원, 1로 설정하면 2차원에 list 안의 텐서들을 연결한다.\n",
    "\n",
    "tensor2 = torch.ones(4,4)\n",
    "t1 = torch.cat([tensor2, tensor2, tensor2], dim=1)\n",
    "print(t1)\n",
    "print(t1.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3034, 0.2544, 0.0832, 0.6965],\n",
      "        [0.2544, 0.5737, 0.1544, 0.8016],\n",
      "        [0.0832, 0.1544, 0.0565, 0.2521],\n",
      "        [0.6965, 0.8016, 0.2521, 1.7375]])\n",
      "tensor([[0.3034, 0.2544, 0.0832, 0.6965],\n",
      "        [0.2544, 0.5737, 0.1544, 0.8016],\n",
      "        [0.0832, 0.1544, 0.0565, 0.2521],\n",
      "        [0.6965, 0.8016, 0.2521, 1.7375]])\n",
      "tensor([[0.3034, 0.2544, 0.0832, 0.6965],\n",
      "        [0.2544, 0.5737, 0.1544, 0.8016],\n",
      "        [0.0832, 0.1544, 0.0565, 0.2521],\n",
      "        [0.6965, 0.8016, 0.2521, 1.7375]])\n",
      "tensor([[0.2497, 0.0000, 0.0112, 0.0425],\n",
      "        [0.0279, 0.0000, 0.1397, 0.4060],\n",
      "        [0.0066, 0.0000, 0.0388, 0.0111],\n",
      "        [0.9953, 0.0000, 0.2379, 0.5043]])\n",
      "tensor([[0.2497, 0.0000, 0.0112, 0.0425],\n",
      "        [0.0279, 0.0000, 0.1397, 0.4060],\n",
      "        [0.0066, 0.0000, 0.0388, 0.0111],\n",
      "        [0.9953, 0.0000, 0.2379, 0.5043]])\n",
      "tensor([[0.2497, 0.0000, 0.0112, 0.0425],\n",
      "        [0.0279, 0.0000, 0.1397, 0.4060],\n",
      "        [0.0066, 0.0000, 0.0388, 0.0111],\n",
      "        [0.9953, 0.0000, 0.2379, 0.5043]])\n"
     ]
    }
   ],
   "source": [
    "# 두 텐서 간의 행렬 곱(matrix multiplication)을 계산합니다. y1, y2, y3은 모두 같은 값을 갖습니다.\n",
    "y1 = tensor @ tensor.T\n",
    "y2 = tensor.matmul(tensor.T)\n",
    "\n",
    "y3 = torch.rand_like(tensor)\n",
    "torch.matmul(tensor, tensor.T, out=y3)\n",
    "\n",
    "\n",
    "# 요소별 곱(element-wise product)을 계산합니다. z1, z2, z3는 모두 같은 값을 갖습니다.\n",
    "z1 = tensor * tensor\n",
    "z2 = tensor.mul(tensor)\n",
    "\n",
    "z3 = torch.rand_like(tensor)\n",
    "torch.mul(tensor, tensor, out=z3)\n",
    "print(y1)\n",
    "print(y2)\n",
    "print(y3)\n",
    "print(z1)\n",
    "print(z2)\n",
    "print(z3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28556764125823975 <class 'float'>\n",
      "0.28556764125823975\n"
     ]
    }
   ],
   "source": [
    "agg = tensor.mean()\n",
    "agg_item = agg.item()\n",
    "print(agg_item, type(agg_item))\n",
    "\n",
    "print(agg.item())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5.4997, 5.0000, 5.1058, 5.2061],\n",
      "        [5.1672, 5.0000, 5.3738, 5.6372],\n",
      "        [5.0813, 5.0000, 5.1970, 5.1055],\n",
      "        [5.9977, 5.0000, 5.4878, 5.7101]]) \n",
      "\n",
      "tensor([[10.4997, 10.0000, 10.1058, 10.2061],\n",
      "        [10.1672, 10.0000, 10.3738, 10.6372],\n",
      "        [10.0813, 10.0000, 10.1970, 10.1055],\n",
      "        [10.9977, 10.0000, 10.4878, 10.7101]])\n"
     ]
    }
   ],
   "source": [
    "# in-place 연산으로 접미사 '_'를 붙임\n",
    "\n",
    "print(f\"{tensor} \\n\")\n",
    "tensor.add_(5)\n",
    "print(tensor)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### NumPy 변환"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([1., 1., 1., 1., 1.])\n",
      "n: [1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# cpu 상의 텐서와 numpy 배열은 메모리 공간을 공유하기 때문에, 하나를 변경하면 다른 하나도 변경된다.\n",
    "\n",
    "t = torch.ones(5)\n",
    "print(f\"t: {t}\")\n",
    "n = t.numpy()\n",
    "print(f\"n: {n}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([2., 2., 2., 2., 2.])\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "t.add_(1)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "n = np.ones(5)\n",
    "t = torch.from_numpy(n)\n",
    "\n",
    "print(t)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "np.add(n, 1, out=n)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}